# Representation Learning Q&A

##### What is representation learning? Why is it useful? (for a particular architecture, for other tasks, etc.)
##### What is the relation between Representation Learning and Deep Learning?
##### What is one-shot and zero-shot learning (Google's NMT)? Give examples.
##### What trade offs does representation learning have to consider?
##### What is greedy layer-wise unsupervised pretraining (GLUP)? Why greedy? Why layer-wise? Why unsupervised? Why pretraining?
##### What were/are the purposes of the above technique? (deep learning problem and initialization)
##### Why does unsupervised pretraining work?
##### When does unsupervised training work? Under which circumstances?
##### Why might unsupervised pretraining act as a regularizer?
##### What is the disadvantage of unsupervised pretraining compared to other forms of unsupervised learning?
##### How do you control the regularizing effect of unsupervised pretraining?
##### How to select the hyperparameters of each stage of GLUP?
