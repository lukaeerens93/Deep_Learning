# Basic Networks
## Table of Contents
1. [ NN Basics. ](#NNBasics)
2. [ Shallow NN. ](#shallow)
3. [ Deep NN. ](#deep)
4. [ Hyperparams. ](#Hyperparams)

<a name="NNBasics"></a>
## 1. Description

##### Binary classification
##### Logistic regression
##### Logistic regression cost function
##### Gradient Descent
##### Derivatives
##### More Derivatives examples
##### Computation graph
##### Derivatives with a Computation Graph
##### Logistic Regression Gradient Descent
##### Gradient Descent on m Examples
##### Vectorization
##### Vectorizing Logistic Regression
##### Notes on Python and NumPy
##### General Notes

<a name="shallow"></a>
## 2. Shallow NN

##### Shallow neural networks
##### Neural Networks Overview
##### Neural Network Representation
##### Computing a Neural Network's Output
##### Vectorizing across multiple examples
##### Activation functions
##### Why do you need non-linear activation functions?
##### Derivatives of activation functions
##### Gradient descent for Neural Networks
##### Random Initialization

<a name="deep"></a>
## 3. Deep NN

##### Deep Neural Networks
##### Deep L-layer neural network
##### Forward Propagation in a Deep Network
##### Getting your matrix dimensions right
##### Why deep representations?
##### Building blocks of deep neural networks
##### Forward and Backward Propagation
##### Parameters vs Hyperparameters
##### What does this have to do with the brain


<a name="Hyperparams"></a>
## 4. Hyperparams

sometext

